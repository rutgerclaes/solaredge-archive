name: Scrape Data
on:
  workflow_dispatch: {}
  schedule:
    - cron: '27 0,12 * * *'
jobs:
  scrape:
    name: Scrape SolarEdge
    runs-on: ubuntu-latest
    env:
      SOLAREDGE_API_TOKEN: "${{ secrets.SOLAREDGE_API_TOKEN }}"
      SOLAREDGE_SITE_ID: "${{ secrets.SOLAREDGE_SITE_ID }}"
    steps:
      - uses: actions/checkout@v3
      - name: Setup Runner
        run: |
          sudo timedatectl set-timezone "Europe/Brussels"
          git config user.name "GitHub Bot"
          git config user.email "<>"
      - name: Scrape SolarEdge API
        run: |
          TIME=$(date "+%Y-%m-%dT%T")
          DATE=$(date "+%Y-%m-%d" -d "$TIME")

          ./archive $DATE
          git add "data/raw/$(date "+%Y/%m/%d" -d "$TIME")"

          YESTERDAY="$(date +"%Y-%m-%d" -d "$TIME 1 day ago")"
          ./archive $YESTERDAY
          git add "data/raw/$(date "+%Y/%m/%d" -d "$TIME 1 day ago")"

          CHANGES=$(git status -s | cut -d " " -f 3)

          echo "# ðŸ¦¾ Scrape Results" >> $GITHUB_STEP_SUMMARY
          if [[ -n "$CHANGES" ]]; then
            echo "## Raw Scrape Results" >> $GITHUB_STEP_SUMMARY
            echo "Files scraped:" >> $GITHUB_STEP_SUMMARY
            echo "${CHANGES/ /$'\n'}" | sed -E 's/^/- /' >> $GITHUB_STEP_SUMMARY

            git commit -m "data: Automatic scrape on ${TIME/T/ }"
            
            echo "## Data Processing" >> $GITHUB_STEP_SUMMARY

            echo "### CSV Processing" >> $GITHUB_STEP_SUMMARY

            for file in $CHANGES; do
              output=$(echo "$file" | sed 's/raw/processed/' | sed 's/.json$/.csv/')
              echo -e "\e[1m[info] Processing '${file}' into '${output}'\e[0m"
              mkdir -p "$(dirname $output)"
              ./process $file > $output
              echo -e "\e[1m[info] Done writing to '${output}'\e[0m"
              echo "- ${file} converted to ${output} ($(cat ${output} | wc -l) lines)" >> $GITHUB_STEP_SUMMARY 
            done;

            echo "### Line Protocol Processing" >> $GITHUB_STEP_SUMMARY

            ENERGY_FILES=$(echo $CHANGES | grep -F "energy.csv" )
            echo "${ENERGY_FILES}"
            echo "\e[1m[info] Energy files: ${ENERGY_FILES}\e[0m"
            for file in $ENERGY_FILES; do
              output=$(echo "$file" | sed 's/energy\.csv/energy.lp/')
              echo -e "\e[1m[info] Processing energy file '${file}' into '${output}'\e[0m"
              ./influx energy energy_wh $file > $output
              git add $output
              echo "- ${file} converted to ${output} ($(cat ${output} | wc -l) lines)" >> $GITHUB_STEP_SUMMARY 
            done;

            POWER_FILES=$(echo $CHANGES | grep -F "power.csv" )
            echo "\e[1m[info] Power files: ${POWER_FILES}\e[0m"
            for file in $POWER_FILES; do
              output=$(echo "$file" | sed 's/power\.csv/power.lp/')
              echo -e "\e[1m[info] Processing power file '${file}' into '${output}'\e[0m"
              ./influx power power_w $file > $output
              git add $output
              echo "- ${file} converted to ${output} ($(cat ${output} | wc -l) lines)" >> $GITHUB_STEP_SUMMARY 
            done;

            git commit -m "data: Automatic processing on ${TIME/T/ }"
            git push origin
          fi
